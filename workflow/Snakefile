##################################################
# Name: Snakefile
# Description: Main workflow for SPUMONI 
#              experiments
# Date: 1/29/22
##################################################

configfile: "config/config.yaml"

import glob
import os

num_datasets = config["NUM_DATASETS"]
base_dir = config["DATA_ROOT"]
repo_dir = config["REPO_DIR"]
spumoni_dir = config["SPUMONI_DIR"]

###############################################################################
# IMPORTANT: Sets the working directory based on configuration parameter, and 
#            it can be set on command-line using --config DATA_ROOT=""
###############################################################################
workdir: config["DATA_ROOT"]

###########################################################
# Helper Functions for Snakemake rules
###########################################################

def get_group_lists(wildcards):
    """ Retuns a list of genomes given a dataset number """
    file_list = []
    for data_file in os.listdir(f"data/dataset_{wildcards.num}"):
        if data_file.endswith(".fna"):
            file_list.append(f"data/dataset_{wildcards.num}/" + data_file)
    return file_list

###########################################################
# Start of Snakemake rules ...
###########################################################

rule produce_list_of_genomes:
    input:
        get_group_lists
    output:
        "step_1/dataset_{num}/dataset_{num}_list.txt"
    run:
        with open(output[0], "w") as fd:
            for file_name in input:
                fd.write(file_name + "\n")
            
rule generate_one_seq_per_group:
    input:
        "step_1/dataset_{num}/dataset_{num}_list.txt"
    output:
        "step_2/dataset_{num}/dataset_{num}.fa"
    shell:
        "while read line; do cat $line >> {output}; done<{input} "

rule generate_rev_comp_for_group:
    input:
        "step_2/dataset_{num}/dataset_{num}.fa"
    output:
        "step_3/dataset_{num}/dataset_{num}_rev_comp.fa"
    shell:
        "seqtk seq -r -U {input} > {output}"

rule generate_combined_seq_for_group:
    input:
        "step_2/dataset_{num}/dataset_{num}.fa",
        "step_3/dataset_{num}/dataset_{num}_rev_comp.fa"
    output:
        "individual_datasets/dataset_{num}/dataset_{num}_combined.fa"
    run:
        shell("cat {input[0]} > {output}")
        shell("sed 's/^>/\>rev_comp_/' {input[1]} >> {output}")
        #with open(output[0], "w") as output_fd:
        #    forward_seq = open(input[0], "r").readlines()[1].strip()
        #    rev_comp_seq = open(input[1], "r").readlines()[1].strip()
            
        #    output_fd.write(f">dataset_{wildcards.num}\n")
        #    output_fd.write(forward_seq + rev_comp_seq + '\n')

rule generate_full_reference:
    input:
        expand("individual_datasets/dataset_{num}/dataset_{num}_combined.fa", num=range(1, num_datasets+1))
    output:
        "combined_dataset/full_dataset.fa"
    shell:
        "cat {input} > {output}"

rule build_fasta_index:
    input:
        "combined_dataset/full_dataset.fa"
    output:
        "combined_dataset/full_dataset.fa.fai"
    shell:
        "samtools faidx {input}"

rule build_spumoni_index:
    input:
        "combined_dataset/full_dataset.fa",
        "combined_dataset/full_dataset.fa.fai"
    output:
        "combined_dataset/full_dataset.fa.thrbv.ms",
        "combined_dataset/full_dataset.fa.thrbv.spumoni"
    run:
        shell("spumoni build -r {input[0]}  -M -P -f -d")

